<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Stay tuned"><title>TensorFlow-学习笔记(2) | 大腿成长记</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">TensorFlow-学习笔记(2)</h1><a id="logo" href="/.">大腿成长记</a><p class="description">Keep my dream alive, what if it come true?</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">TensorFlow-学习笔记(2)</h1><div class="post-meta">Apr 30, 2017<span> | </span><span class="category"><a href="/categories/TensorFlow/">TensorFlow</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-disqus-identifier="TensorFlow/TensorFlow-学习笔记-2/" href="/TensorFlow/TensorFlow-学习笔记-2/#disqus_thread" class="disqus-comment-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#TF-Convolution-Layer"><span class="toc-number">1.</span> <span class="toc-text">TF Convolution Layer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pooling"><span class="toc-number">2.</span> <span class="toc-text">Pooling</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Walk-Through-MNIST-again-with-CNN"><span class="toc-number">3.</span> <span class="toc-text">Walk Through MNIST again with CNN</span></a></li></ol></div></div><div class="post-content"><h2 id="TF-Convolution-Layer"><a href="#TF-Convolution-Layer" class="headerlink" title="TF Convolution Layer"></a>TF Convolution Layer</h2><p> <code>tf.nn.conv2d()</code> and <code>tf.nn.bias_add()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># input/Image</span></div><div class="line">input = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, image_height, image_width, 		 											color_channels])</div><div class="line"><span class="comment"># weight and bias </span></div><div class="line">weight = tf.Variable(tf.truncated_normal(</div><div class="line">    [filter_size_height, filter_size_width, color_channels, k_output]))</div><div class="line">bias = tf.Variable(tf.zeros(k_output))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W, b, stride=<span class="number">1</span>)</span>:</span></div><div class="line">    x = tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, stride, stride, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</div><div class="line">    x = tf.nn.bias_add(x, b)</div><div class="line">    <span class="keyword">return</span> tf.nn.relu(x) </div><div class="line"></div><div class="line">conv_layer = conv2d(input, weight, bias, strides=<span class="number">2</span>)</div></pre></td></tr></table></figure>
<p><code>padding</code> can be <code>&#39;SAME&#39;</code>or <code>&#39;VALID&#39;</code></p>
<h2 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Pooling</h2><p>Conceptually, the benefit of the max pooling operation is to <strong>reduce the size of the input</strong>(which can help prevent overfitting), and allow the neural network to focus on only the <strong>most important elements</strong>. Max pooling does this by only retaining the maximum value for each filtered area, and removing the remaining values.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxpool2d</span><span class="params">(x, k=<span class="number">2</span>)</span>:</span></div><div class="line">    <span class="keyword">return</span> tf.nn.max_pool(x,ksize=[<span class="number">1</span>, k, k, <span class="number">1</span>],strides=[<span class="number">1</span>, k, k, <span class="number">1</span>],padding=<span class="string">'SAME'</span>)</div></pre></td></tr></table></figure>
<p>4 element lists of <code>ksize</code> and <code>strides</code> corresponde to the dimension of the input tensor ([batch, height, width, channels]), batch and channel dimensions are typically set to <code>1</code>.</p>
<p>Recently, pooling layers have fallen out of favor. Some reasons are:</p>
<ul>
<li>Recent datasets are so big and complex we’re more concerned about underfitting.</li>
<li>Dropout is a much better regularizer.</li>
<li>Pooling results in a loss of information. Think about the max pooling operation as an example. We only keep the largest of <em>n</em> numbers, thereby disregarding <em>n-1</em> numbers completely.</li>
</ul>
<h2 id="Walk-Through-MNIST-again-with-CNN"><a href="#Walk-Through-MNIST-again-with-CNN" class="headerlink" title="Walk Through MNIST again with CNN"></a>Walk Through MNIST again with CNN</h2><p>Define the <strong>model</strong>: </p>
<p><img src="http://ww1.sinaimg.cn/large/006tNbRwgy1ff51ax761aj30xu0g00vc.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Store layers weight &amp; bias</span></div><div class="line"><span class="comment"># [filter_size_height, filter_size_width, color_channels, k_output]</span></div><div class="line">weights = &#123;</div><div class="line">    <span class="string">'wc1'</span>: tf.Variable(tf.random_normal([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>])),</div><div class="line">    <span class="string">'wc2'</span>: tf.Variable(tf.random_normal([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>])),</div><div class="line">    <span class="string">'wd1'</span>: tf.Variable(tf.random_normal([<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>, <span class="number">1024</span>])),</div><div class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([<span class="number">1024</span>, n_classes]))&#125;</div><div class="line"></div><div class="line">biases = &#123;</div><div class="line">    <span class="string">'bc1'</span>: tf.Variable(tf.random_normal([<span class="number">32</span>])),</div><div class="line">    <span class="string">'bc2'</span>: tf.Variable(tf.random_normal([<span class="number">64</span>])),</div><div class="line">    <span class="string">'bd1'</span>: tf.Variable(tf.random_normal([<span class="number">1024</span>])),</div><div class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([n_classes]))&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_net</span><span class="params">(x, weights, biases, dropout)</span>:</span></div><div class="line">    <span class="comment"># Layer 1 - 28*28*1 to 14*14*32</span></div><div class="line">    conv1 = conv2d(x, weights[<span class="string">'wc1'</span>], biases[<span class="string">'bc1'</span>])</div><div class="line">    conv1 = maxpool2d(conv1, k=<span class="number">2</span>)</div><div class="line"></div><div class="line">    <span class="comment"># Layer 2 - 14*14*32 to 7*7*64</span></div><div class="line">    conv2 = conv2d(conv1, weights[<span class="string">'wc2'</span>], biases[<span class="string">'bc2'</span>])</div><div class="line">    conv2 = maxpool2d(conv2, k=<span class="number">2</span>)</div><div class="line"></div><div class="line">    <span class="comment"># Fully connected layer - 7*7*64 to 1024</span></div><div class="line">    fc1 = tf.reshape(conv2, [<span class="number">-1</span>, weights[<span class="string">'wd1'</span>].get_shape().as_list()[<span class="number">0</span>]])</div><div class="line">    fc1 = tf.add(tf.matmul(fc1, weights[<span class="string">'wd1'</span>]), biases[<span class="string">'bd1'</span>])</div><div class="line">    fc1 = tf.nn.relu(fc1)</div><div class="line">    fc1 = tf.nn.dropout(fc1, dropout)</div><div class="line"></div><div class="line">    <span class="comment"># Output Layer - class prediction - 1024 to 10</span></div><div class="line">    out = tf.add(tf.matmul(fc1, weights[<span class="string">'out'</span>]), biases[<span class="string">'out'</span>])</div><div class="line">    <span class="keyword">return</span> out</div></pre></td></tr></table></figure>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://yuanfresa.github.io/TensorFlow/TensorFlow-学习笔记-2/" data-id="cj25al6j3000562pn3mh8rqb4" class="article-share-link">Share</a><div class="tags"><a href="/tags/deep-learning/">deep learning</a></div><div class="post-nav"><a href="/TensorFlow/Preprocessing-the-Data/" class="next">Preprocessing the Data</a></div><div id="disqus_thread"><script>var disqus_shortname = 'yuanfresa';
var disqus_identifier = 'TensorFlow/TensorFlow-学习笔记-2/';
var disqus_title = 'TensorFlow-学习笔记(2)';
var disqus_url = 'http://yuanfresa.github.io/TensorFlow/TensorFlow-学习笔记-2/';
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//yuanfresa.disqus.com/count.js" async></script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yuanfresa.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/CS231n-notebook/">CS231n notebook</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/TensorFlow/">TensorFlow</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper-notes/">paper notes</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/生命在于折腾/">生命在于折腾</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/deep-learning/" style="font-size: 15px;">deep learning</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/TensorFlow/TensorFlow-学习笔记-2/">TensorFlow-学习笔记(2)</a></li><li class="post-list-item"><a class="post-list-link" href="/TensorFlow/Preprocessing-the-Data/">Preprocessing the Data</a></li><li class="post-list-item"><a class="post-list-link" href="/paper-notes/关于-Batch-Normalization/">关于 Batch Normalization</a></li><li class="post-list-item"><a class="post-list-link" href="/TensorFlow/TensorFlow-学习笔记-1/">TensorFlow 学习笔记(1)</a></li><li class="post-list-item"><a class="post-list-link" href="/CS231n-notebook/CS231n-Neural-Network-part3-Learning-and-Evaluation-总结笔记/">CS231n-Neural-Network-part3-Learning-and-Evaluation-总结笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/CS231n-notebook/CS231n-Neural-Network-part2-Setting-up-the-data-and-the-model-总结笔记/">CS231n-Neural-Network-part2-Setting-up-the-data and the model-总结笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/生命在于折腾/hexo填坑记/">hexo填坑记</a></li><li class="post-list-item"><a class="post-list-link" href="/CS231n-notebook/CS231n-Neural-Network-part1-Setting-up-the-Architecture-总结笔记/">CS231n Neural Network part1: Setting up the Architecture 总结笔记</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> Recent Comments</i></div><script type="text/javascript" src="//yuanfresa.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/yuanfresa" title="github" target="_blank">github</a><ul></ul><a href="https://www.zhihu.com/people/yumemor" title="zhihu" target="_blank">zhihu</a><ul></ul><a href="https://twitter.com/Yuan_Fresa/" title="twitter" target="_blank">twitter</a><ul></ul><a href="https://www.facebook.com/yuan.zhou.31392" title="facebook" target="_blank">facebook</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a>2017 </a><a href="/." rel="nofollow">大腿成长记.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>